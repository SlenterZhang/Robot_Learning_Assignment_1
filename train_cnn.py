"""Train a CNN policy: image -> LQR action.

This trains a convolutional network to regress the expert torque from a single
rendered observation image.

Requires images generated by collect_lqr_data.py under data/images/.

Usage:
  python train_cnn.py --data data/lqr_dataset.npz --img_root data/images --out models/cnn.pt
"""

import argparse
import os
import re
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from policies import CNNPolicy
from PIL import Image


class ImageActionDataset(Dataset):
    def __init__(self, npz_path: str, img_root: str, split: str = "train", train_frac: float = 0.9, seed: int = 0):
        d = np.load(npz_path, allow_pickle=True)
        actions = d["actions"]  # (num_traj, N)
        num_traj, N = actions.shape

        # Build (path, action) list
        items = []
        for i in range(num_traj):
            traj_dir = os.path.join(img_root, f"traj_{i:02d}")
            for t in range(N):
                p = os.path.join(traj_dir, f"frame_{t:04d}.png")
                items.append((p, float(actions[i, t])))

        rng = np.random.default_rng(seed)
        idx = np.arange(len(items))
        rng.shuffle(idx)
        n_train = int(train_frac * len(idx))
        sel = idx[:n_train] if split == "train" else idx[n_train:]

        self.items = [items[j] for j in sel]

    def __len__(self):
        return len(self.items)

    def __getitem__(self, i):
        path, a = self.items[i]
        img = Image.open(path).convert("RGB")
        x = np.asarray(img, dtype=np.float32) / 255.0  # HWC
        x = np.transpose(x, (2, 0, 1))  # CHW
        return torch.from_numpy(x), torch.tensor([a], dtype=torch.float32)


def train(args):
    device = torch.device("cuda" if torch.cuda.is_available() and not args.cpu else "cpu")

    ds_train = ImageActionDataset(args.data, args.img_root, split="train", train_frac=args.train_frac, seed=args.seed)
    ds_val = ImageActionDataset(args.data, args.img_root, split="val", train_frac=args.train_frac, seed=args.seed)

    train_loader = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(ds_val, batch_size=args.batch_size, shuffle=False, num_workers=0)

    model = CNNPolicy().to(device)
    opt = torch.optim.Adam(model.parameters(), lr=args.lr)
    loss_fn = nn.MSELoss()

    train_losses, val_losses = [], []
    for epoch in range(1, args.epochs + 1):
        model.train()
        total = 0.0
        for x, y in train_loader:
            # x - data, y - label
            x, y = x.to(device), y.to(device)

            # Backpropagation
            ###################################
            #  TODO4.3: write your code here  #
            ###################################  
            # HINT: first forward pass, compute loss, zero_grad, and backward and step the optimizer
            pred = model(x)
            loss = loss_fn(pred, y)

            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()

            total += loss.item() * x.shape[0]
        train_loss = total / len(ds_train)

        model.eval()
        total = 0.0
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(device), y.to(device)
                pred = model(x)
                loss = loss_fn(pred, y)
                total += loss.item() * x.shape[0]
        val_loss = total / len(ds_val)

        train_losses.append(train_loss)
        val_losses.append(val_loss)
        if epoch % args.print_every == 0 or epoch == 1 or epoch == args.epochs:
            print(f"Epoch {epoch:04d} | train {train_loss:.6f} | val {val_loss:.6f}")

    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    ckpt = {
        "type": "cnn",
        "model_state": model.state_dict(),
        "config": vars(args),
        "train_losses": train_losses,
        "val_losses": val_losses,
    }
    torch.save(ckpt, args.out)
    print(f"Saved: {args.out}")


def main():
    p = argparse.ArgumentParser()
    p.add_argument("--data", type=str, default="data/lqr_dataset.npz")
    p.add_argument("--img_root", type=str, default="data/images")
    p.add_argument("--out", type=str, default="models/cnn.pt")
    p.add_argument("--epochs", type=int, default=10)
    p.add_argument("--batch_size", type=int, default=128)
    p.add_argument("--lr", type=float, default=1e-3)
    p.add_argument("--train_frac", type=float, default=0.9)
    p.add_argument("--seed", type=int, default=0)
    p.add_argument("--print_every", type=int, default=1)
    p.add_argument("--cpu", action="store_true")
    args = p.parse_args()
    train(args)


if __name__ == "__main__":
    main()
